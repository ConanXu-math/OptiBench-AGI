{
  "paper_name": "Max-Weight Revisited: Sequences of Non-Convex Optimisations Solving Convex Optimisations",
  "arxiv_id": "1406.0899v4",
  "outline": {
    "objective": "\\min_{z \\in \\mathcal{C}} f(z)",
    "constraints": [
      "g(z) \\preceq 0"
    ],
    "variables": [
      "z",
      "x",
      "\\lambda",
      "\\beta",
      "\\alpha"
    ],
    "notation_table": [
      {
        "symbol": "z",
        "dimension": "n",
        "description": "Decision variables: primal variable sequence, running average"
      },
      {
        "symbol": "x",
        "dimension": "|D|",
        "description": "Decision variables: action set"
      },
      {
        "symbol": "f(z)",
        "dimension": "1",
        "description": "Primal objective function"
      },
      {
        "symbol": "g(z)",
        "dimension": "m",
        "description": "Constraint functions (vector of m functions)"
      },
      {
        "symbol": "\\lambda",
        "dimension": "m",
        "description": "Lagrange multiplier vector"
      },
      {
        "symbol": "\\bar{z}",
        "dimension": "n",
        "description": "Slater point"
      },
      {
        "symbol": "\\bar{\\lambda}",
        "dimension": "1",
        "description": "Upper bound on Lagrange multipliers"
      },
      {
        "symbol": "\\alpha",
        "dimension": "1",
        "description": "Parameter controlling step size in dual update"
      },
      {
        "symbol": "\\beta",
        "dimension": "1",
        "description": "Parameter controlling smoothing/step size in primal update"
      },
      {
        "symbol": "\\mu_f",
        "dimension": "1",
        "description": "Curvature constant of f"
      },
      {
        "symbol": "\\mu_g",
        "dimension": "m",
        "description": "Curvature constants of constraint functions (vector)"
      },
      {
        "symbol": "\\bar{g}",
        "dimension": "1",
        "description": "Maximum norm of g(z) over feasible set C"
      },
      {
        "symbol": "\\bar{x}_D",
        "dimension": "1",
        "description": "Maximum Euclidean norm of points in D"
      }
    ]
  },
  "prove_cot": "",
  "pseudocode": "Algorithm: Primal-Dual Optimization with Smoothed Updates\n\nInput: feasible region C, objective f(z), constraint functions g(z), parameters α, β, seed for data generation\n\n1. Initialize:\n   - z₀ ∈ C (feasible point)\n   - λ₀ = 0 (Lagrange multipliers)\n   - x ← sample from D (action set, if needed)\n\n2. For iter = 1 to max_iterations:\n   a. Compute primal gradient ∇f(z_{iter-1})\n   b. Compute dual gradient ∇λ g(z_{iter-1})\n   c. Update z using smoothed primal step:\n        z_{iter} = z_{iter-1} - β * (∇f + λ_{iter-1}^T ∇g)\n   d. Update λ using projected dual step:\n        λ_{iter} = proj_{[0, “barλ”]}(λ_{iter-1} + α * g(z_{iter}))\n   e. Check convergence: ||z_{iter} - z_{iter-1}|| < tolerance or max_iters reached\n\n3. Return z_final, f(z_final) as optimal solution and value\n\nNote: Slater condition must hold; g(z) ≤ 0 over C, and “bar{z}” is a strictly feasible interior point.\n",
  "pycode": "import numpy as np\nfrom scipy.optimize import minimize\nimport warnings\n\n# Generate synthetic test instance\ndef generate_synthetic_data(seed: int = 42) -> dict:\n    np.random.seed(seed)\n    n, m = 5, 3  # dimensions for z and constraints\n\n    # Define action set D (for x variable)\n    D = np.random.randn(10, n)  # |D| = 10 actions\n    bar_x_D = np.linalg.norm(D, axis=1).max()  # maximum Euclidean norm of points in D\n\n    # Define feasibility region C\n    # Use quadratic constraints for simplicity, ensuring Slater point exists\n    Q = np.eye(n)  # identity matrix\n    A = np.random.randn(m, n)  # constraint matrix\n    b = np.ones(m)  # right-hand side\n    bar_z = np.zeros(n)  # Slater point: satisfies A@bar_z < b\n    \n    # Ensure bar_z is strictly feasible\n    while np.any(A @ bar_z >= b):\n        bar_z += 0.1 * np.random.randn(n)\n    \n    # Define curvature constants μ_f, μ_g\n    mu_f = 1.0  # curvature constant for f\n    mu_g = np.ones(m)  # vector of curvature constants\n    \n    # Define upper bound on Lagrange multipliers\n    bar_lambda = 10.0\n    \n    # Parameters α (dual step size), β (primal step size)\n    alpha = 0.1\n    beta = 0.5\n\n    return {\n        'z': np.zeros(n),  # initial z\n        'x': D,            # action set\n        'lambda': np.zeros(m),\n        'beta': beta,\n        'alpha': alpha,\n        'mu_f': mu_f,\n        'mu_g': mu_g,\n        'bar_z': bar_z,\n        'bar_lambda': bar_lambda,\n        'bar_x_D': bar_x_D,\n        'A': A,             # constraint matrix\n        'b': b,             # right-hand side\n        'm': m,             # number of constraints\n        'n': n              # dimension of z\n    }\n\n# Solve the optimization problem\ndef solve(data: dict) -> dict:\n    \n    z_initial = data['z']\n    A = data['A']\n    b = data['b']\n    n = data['n']\n    m = data['m']\n    alpha = data['alpha']\n    beta = data['beta']\n    mu_f = data['mu_f']\n    mu_g = data['mu_g']\n    bar_lambda = data['bar_lambda']\n    bar_z = data['bar_z']\n    \n    def objective(z):\n        # Simple quadratic function f(z) = ||z||²/2 + linear term to make it non-trivial\n        q = 0.5 * np.dot(z, z)  # convex part\n        linear_term = -np.sum(z[:n])  # additive linear component\n        return q + linear_term\n\n    def constraint_function(x):\n        # Vector of constraint values: g(z) <= 0\n        return A @ x  # returns an array of shape (m, ) → needs to be <= 0\n\n    # Define constrained minimization problem\n    res = minimize(\n        fun=objective,\n        x0=z_initial,\n        method='SLSQP',\n        constraints={'type': 'ineq', 'fun': lambda x: -constraint_function(x)},\n        options={'disp': False, 'ftol': 1e-6, 'eps': 1e-9}\n    )\n    \n    if not res.success:\n        warnings.warn(f\"Solver failed: {res.message}\")\n        # Fallback: use feasible point as solution\n        solution = bar_z\n        optimal_value = objective(solution)\n    else:\n        solution = res.x\n        optimal_value = res.fun\n\n    # Prepare output with minimal structure required\n    result = {\n        'optimal_value': float(optimal_value),\n        'solution': solution.tolist(),\n        'success': res.success,\n        'message': res.message\n    }\n    \n    return result\n\nif __name__ == '__main__':\n    # Generate test data\n    data = generate_synthetic_data()\n    print(\"Generated Data:\")\n    for key, val in data.items():\n        print(f\"{key}: shape={val.shape if isinstance(val, np.ndarray) else type(val)}\")\n\n    # Solve\n    solution_dict = solve(data)\n    \n    print('\\nSolution:')\n    print(f\"Optimal Value: {solution_dict['optimal_value']:.6f}\")\n    print(f\"Solution Vector (z): {solution_dict['solution']}\\n\")",
  "lean4_formal": ""
}