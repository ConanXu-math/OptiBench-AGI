Algorithm: Primal-Dual Optimization with Smoothed Updates

Input: feasible region C, objective f(z), constraint functions g(z), parameters α, β, seed for data generation

1. Initialize:
   - z₀ ∈ C (feasible point)
   - λ₀ = 0 (Lagrange multipliers)
   - x ← sample from D (action set, if needed)

2. For iter = 1 to max_iterations:
   a. Compute primal gradient ∇f(z_{iter-1})
   b. Compute dual gradient ∇λ g(z_{iter-1})
   c. Update z using smoothed primal step:
        z_{iter} = z_{iter-1} - β * (∇f + λ_{iter-1}^T ∇g)
   d. Update λ using projected dual step:
        λ_{iter} = proj_{[0, “barλ”]}(λ_{iter-1} + α * g(z_{iter}))
   e. Check convergence: ||z_{iter} - z_{iter-1}|| < tolerance or max_iters reached

3. Return z_final, f(z_final) as optimal solution and value

Note: Slater condition must hold; g(z) ≤ 0 over C, and “bar{z}” is a strictly feasible interior point.
